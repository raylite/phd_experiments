{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACINHIBITOR RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the models in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import logging\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "from gensim import models, corpora\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "print (\"Required Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import file in cvs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Label</th>\n",
       "      <th>TIABSMh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10099033</td>\n",
       "      <td>0</td>\n",
       "      <td>Effects of delapril in combination with indapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10099034</td>\n",
       "      <td>0</td>\n",
       "      <td>Clinical and neurohormonal effects of nicardip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10099064</td>\n",
       "      <td>0</td>\n",
       "      <td>Effect of benazepril on endothelial function i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10099075</td>\n",
       "      <td>0</td>\n",
       "      <td>Lowdose combination treatment for hypertension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10130617</td>\n",
       "      <td>0</td>\n",
       "      <td>Development implementation and results of a su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID  Label                                            TIABSMh\n",
       "0  10099033      0  Effects of delapril in combination with indapa...\n",
       "1  10099034      0  Clinical and neurohormonal effects of nicardip...\n",
       "2  10099064      0  Effect of benazepril on endothelial function i...\n",
       "3  10099075      0  Lowdose combination treatment for hypertension...\n",
       "4  10130617      0  Development implementation and results of a su..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data and explore the first few rows\n",
    "# Import the data and explore the first few rows\n",
    "\n",
    "inhibitor  = pd.read_csv(\"C:\\EPC_Data\\TREC_BROKEN\\No_Mh_Tag/aceinhibitor_no_mh.csv\", sep=\",\")#, index_col = \"PMID\")\n",
    "header = inhibitor.columns.values\n",
    "inhibitor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import articles for string cleaning\n",
    "\n",
    "def clean_text(text, stem_words = False, remove_stopwords = False):\n",
    "    ###clean\n",
    "    texts = re.sub(\"[^a-zA-Z]\",    #pattern to match\n",
    "              \" \",              #replace other with this\n",
    "              str(text))                 #text to apply to\n",
    "         \n",
    "    #print \"Text recived: \", texts \n",
    "    clean_corpus = texts.lower().split()\n",
    "    #print \"corpus: \", clean_corpus\n",
    "    if stem_words:\n",
    "        # Porter stemmer\n",
    "        porter = nltk.PorterStemmer()\n",
    "        # Snowball stemmer\n",
    "        snowball = nltk.SnowballStemmer('english')\n",
    "        # Lancaster stemmer\n",
    "        lancaster = nltk.LancasterStemmer()\n",
    "        # General stemming Lambda function to stem tokens\n",
    "        clean_corpus = lambda tokens: [porter.stem(w) for w in corpus]\n",
    "    if remove_stopwords:   # Optionally remove stop words\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        clean_corpus = [w for w in clean_corpus if not w in stops]\n",
    "        #print \"Clean_corpus: \", clean_corpus\n",
    "    \n",
    "    return (clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning texts\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# \n",
    "print (\"Cleaning texts\")\n",
    "cleaned_articles = []\n",
    "for article in inhibitor.TIABSMh:\n",
    "    cleaned_articles.append(clean_text(article, stem_words=False, remove_stopwords=True ))\n",
    "    \n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in cleaned_articles:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in cleaned_articles]\n",
    "\n",
    "#from pprint import pprint  # pretty-printer\n",
    "#pprint(texts)\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(10730 unique tokens: [u'pacemaker', u'telmisartan', u'narcotic', u'four', u'arteriosclerosisblooddrug']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\LSI/dict/aceinhibitor.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#print(dictionary.token2id)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\LSI/dict/aceinhibitor.mm', corpus)  # store to disk, for later use\n",
    "#print(corpus)\n",
    "print (\"Done\")\n",
    "\n",
    "#scipy_csc_matrix = gensim.matutils.corpus2csc(corpus) #convert to a scipy sparse matrix\n",
    "#numpy_matrix = gensim.matutils.corpus2dense(corpus, num_terms=number_of_corpus_features) #convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#automate this for all files."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
