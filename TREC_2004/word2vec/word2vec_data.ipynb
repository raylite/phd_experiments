{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required Libraries loaded.\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load English stopwords from NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize, RegexpTokenizer, WhitespaceTokenizer\n",
    "import nltk.data\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "\n",
    "import os\n",
    "\n",
    "print (\"Required Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import articles for string cleaning\n",
    "\n",
    "def clean_text(text, stem_words = False, remove_stopwords = False):\n",
    "    ###clean\n",
    "    texts = re.sub(\"[^a-zA-Z]\",    #pattern to match\n",
    "              \" \",              #replace other with this\n",
    "              str(text))                 #text to apply to\n",
    "         \n",
    "    #print \"Text recived: \", texts \n",
    "    clean_corpus = texts.lower().split()\n",
    "    #print \"corpus: \", clean_corpus\n",
    "    if stem_words:\n",
    "        # Porter stemmer\n",
    "        porter = nltk.PorterStemmer()\n",
    "        # Snowball stemmer\n",
    "        snowball = nltk.SnowballStemmer('english')\n",
    "        # Lancaster stemmer\n",
    "        lancaster = nltk.LancasterStemmer()\n",
    "        # General stemming Lambda function to stem tokens\n",
    "        clean_corpus = lambda tokens: [porter.stem(w) for w in corpus]\n",
    "    if remove_stopwords:   # Optionally remove stop words\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        clean_corpus = [w for w in clean_corpus if not w in stops]\n",
    "        #print \"Clean_corpus: \", clean_corpus\n",
    "    \n",
    "    return (clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the punkt tokenizer for sentence splitting\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def article_to_sentences(article, tokenizer, stem_words=False, remove_stopwords=False):\n",
    "    \"\"\"\n",
    "    article - article to use as input to create the wordlist\n",
    "    tokenizer - the tokenizer to use to split into sentences\n",
    "    stem_words - boolean, whether to use the stemmer function or not\n",
    "    remove_stopwords - boolean, whether to remove the stopwords function or not\n",
    "    \n",
    "    article_to_sentences: Function to convert a document to a sequence of sentences,\n",
    "    optionally removing stop words.  \n",
    "    returns: a sequence of sentences where each sentence is itself a sequence of words\n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(article.strip())   # Punkt tokenize into sentences\n",
    "    sentences = []   # create list of sentences \n",
    "    for raw_sentence in raw_sentences:\n",
    "        #print \"raw sentence: \", raw_sentence\n",
    "        #print len(raw_sentence)\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append(clean_text(raw_sentence, stem_words, remove_stopwords))\n",
    "\n",
    "    # returns a list of lists: list of sentences composed of lists of words\n",
    "        #print \"Sentences: \", sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sentences(corpus, name):\n",
    "    print (\"Begin sentences creation %s...\" % name)\n",
    "    sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "    print (\"Parsing sentences from training set\")\n",
    "    for article in corpus:\n",
    "        sentences += article_to_sentences(article, tokenizer)\n",
    "    print (\"Finished data loading and creating sentences\")\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "def train_save_model(sentences, filename):\n",
    "\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
    "\n",
    "    # Set values for various parameters\n",
    "    #num_features = 210    # Word vector dimensionality                      \n",
    "    min_word_count = 10   # Minimum word count                        \n",
    "    num_workers = 8       # Number of threads to run in parallel\n",
    "    context = 15          # Context window size                                                                                    \n",
    "    downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "    # Initialize and train the model (this will take some time)\n",
    "\n",
    "    print (\"Training model...\")\n",
    "    if (filename == \"aceinhibitor\"):\n",
    "        num_features = 210\n",
    "    elif (filename == \"adhd\"):\n",
    "        num_features = 80\n",
    "    elif (filename == \"antihistamines\"):\n",
    "        num_features = 29\n",
    "    elif (filename == \"atypicalAntipsychotics\"):\n",
    "        num_features = 381\n",
    "    elif (filename == \"betaBlockers\"):\n",
    "        num_features = 194\n",
    "    elif (filename == \"calciumChannelBlockers\"):\n",
    "        num_features = 329\n",
    "    elif (filename == \"estrogens\"):\n",
    "        num_features = 233\n",
    "    elif (filename == \"nsaids\"):\n",
    "        num_features = 242\n",
    "    elif (filename == \"opiods\"):\n",
    "        num_features = 55\n",
    "    elif (filename == \"oralHypoglycemics\"):\n",
    "        num_features = 234\n",
    "    elif (filename == \"protonPumpInhibitors\"):\n",
    "        num_features = 206\n",
    "    elif (filename == \"skeletalMuscleRelaxants\"):\n",
    "        num_features = 11\n",
    "    elif (filename == \"statins\"):\n",
    "        num_features = 467\n",
    "    elif (filename == \"triptans\"):\n",
    "        num_features = 121\n",
    "    elif (filename == \"urinaryIncontinence\"):\n",
    "        num_features = 215\n",
    "    model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, \n",
    "                              window = context, sample = downsampling)\n",
    "\n",
    "    # If you don't plan to train the model any further, calling \n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    # It can be helpful to create a meaningful model name and \n",
    "    # save the model for later use. You can load it later using Word2Vec.load()\n",
    "    \n",
    "    model_name = filename + \"_chi2_features_10minwords_15context\"\n",
    "    folder = \"C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\"\n",
    "    print (\"Saving the model: %s....\" % model_name)\n",
    "    model_name = os.path.join(folder, model_name)\n",
    "    model.save(model_name)\n",
    "\n",
    "    print (\"Finished Model training and saving for %s...\") % filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin sentences creation aceinhibitor...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:50,151 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:00:50,151 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:00:50,151 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:00:50,196 : INFO : PROGRESS: at sentence #10000, processed 253082 words, keeping 11950 word types\n",
      "2017-01-23 18:00:50,230 : INFO : PROGRESS: at sentence #20000, processed 504463 words, keeping 16753 word types\n",
      "2017-01-23 18:00:50,252 : INFO : collected 18630 word types from a corpus of 633837 raw words and 24993 sentences\n",
      "2017-01-23 18:00:50,276 : INFO : min_count=10 retains 3900 unique words (drops 14730)\n",
      "2017-01-23 18:00:50,276 : INFO : min_count leaves 599341 word corpus (94% of original 633837)\n",
      "2017-01-23 18:00:50,288 : INFO : deleting the raw counts dictionary of 18630 items\n",
      "2017-01-23 18:00:50,292 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2017-01-23 18:00:50,292 : INFO : downsampling leaves estimated 458832 word corpus (76.6% of prior 599341)\n",
      "2017-01-23 18:00:50,295 : INFO : estimated required memory for 3900 words and 210 dimensions: 8502000 bytes\n",
      "2017-01-23 18:00:50,309 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:50,362 : INFO : training model with 8 workers on 3900 vocabulary and 210 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:00:50,364 : INFO : expecting 24993 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-23 18:00:51,469 : INFO : PROGRESS: at 65.50% examples, 1480399 words/s, in_qsize 0, out_qsize 0\n",
      "2017-01-23 18:00:52,032 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:00:52,042 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:00:52,043 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:00:52,049 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:00:52,052 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:00:52,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:00:52,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:00:52,059 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:00:52,059 : INFO : training on 3169185 raw words (2294401 effective words) took 1.6s, 1428008 effective words/s\n",
      "2017-01-23 18:00:52,061 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:00:52,088 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\aceinhibitor_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:00:52,089 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:00:52,091 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: aceinhibitor_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for aceinhibitor...\n",
      "Begin sentences creation adhd...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:52,851 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:00:52,851 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:00:52,891 : INFO : collected 10626 word types from a corpus of 214896 raw words and 8900 sentences\n",
      "2017-01-23 18:00:52,903 : INFO : min_count=10 retains 2144 unique words (drops 8482)\n",
      "2017-01-23 18:00:52,905 : INFO : min_count leaves 194197 word corpus (90% of original 214896)\n",
      "2017-01-23 18:00:52,913 : INFO : deleting the raw counts dictionary of 10626 items\n",
      "2017-01-23 18:00:52,914 : INFO : sample=0.001 downsamples 62 most-common words\n",
      "2017-01-23 18:00:52,917 : INFO : downsampling leaves estimated 148129 word corpus (76.3% of prior 194197)\n",
      "2017-01-23 18:00:52,920 : INFO : estimated required memory for 2144 words and 80 dimensions: 2444160 bytes\n",
      "2017-01-23 18:00:52,927 : INFO : resetting layer weights\n",
      "2017-01-23 18:00:52,960 : INFO : training model with 8 workers on 2144 vocabulary and 80 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:00:52,961 : INFO : expecting 8900 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:53,404 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:00:53,404 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:00:53,404 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:00:53,404 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:00:53,404 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:00:53,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:00:53,414 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:00:53,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:00:53,414 : INFO : training on 1074480 raw words (740802 effective words) took 0.4s, 2041971 effective words/s\n",
      "2017-01-23 18:00:53,414 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:00:53,440 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\adhd_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:00:53,441 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:00:53,443 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: adhd_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for adhd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:53,834 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:00:53,844 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:00:53,844 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin sentences creation antihistamines...\n",
      "Parsing sentences from training set\n",
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:53,854 : INFO : collected 6224 word types from a corpus of 74720 raw words and 3091 sentences\n",
      "2017-01-23 18:00:53,865 : INFO : min_count=10 retains 987 unique words (drops 5237)\n",
      "2017-01-23 18:00:53,868 : INFO : min_count leaves 62623 word corpus (83% of original 74720)\n",
      "2017-01-23 18:00:53,874 : INFO : deleting the raw counts dictionary of 6224 items\n",
      "2017-01-23 18:00:53,875 : INFO : sample=0.001 downsamples 67 most-common words\n",
      "2017-01-23 18:00:53,878 : INFO : downsampling leaves estimated 44141 word corpus (70.5% of prior 62623)\n",
      "2017-01-23 18:00:53,882 : INFO : estimated required memory for 987 words and 29 dimensions: 722484 bytes\n",
      "2017-01-23 18:00:53,891 : INFO : resetting layer weights\n",
      "2017-01-23 18:00:53,911 : INFO : training model with 8 workers on 987 vocabulary and 29 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:00:53,913 : INFO : expecting 3091 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-23 18:00:54,086 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:00:54,086 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:00:54,086 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:00:54,096 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:00:54,096 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:00:54,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:00:54,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:00:54,096 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:00:54,107 : INFO : training on 373600 raw words (220753 effective words) took 0.1s, 1977142 effective words/s\n",
      "2017-01-23 18:00:54,108 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-01-23 18:00:54,108 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:00:54,117 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\antihistamines_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:00:54,118 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:00:54,118 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: antihistamines_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for antihistamines...\n",
      "Begin sentences creation atypicalAntipsychotics...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:55,144 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:00:55,154 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:00:55,154 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:00:55,190 : INFO : PROGRESS: at sentence #10000, processed 246004 words, keeping 10842 word types\n",
      "2017-01-23 18:00:55,194 : INFO : collected 11162 word types from a corpus of 262285 raw words and 10669 sentences\n",
      "2017-01-23 18:00:55,207 : INFO : min_count=10 retains 2255 unique words (drops 8907)\n",
      "2017-01-23 18:00:55,207 : INFO : min_count leaves 241151 word corpus (91% of original 262285)\n",
      "2017-01-23 18:00:55,216 : INFO : deleting the raw counts dictionary of 11162 items\n",
      "2017-01-23 18:00:55,217 : INFO : sample=0.001 downsamples 62 most-common words\n",
      "2017-01-23 18:00:55,219 : INFO : downsampling leaves estimated 180424 word corpus (74.8% of prior 241151)\n",
      "2017-01-23 18:00:55,220 : INFO : estimated required memory for 2255 words and 381 dimensions: 8000740 bytes\n",
      "2017-01-23 18:00:55,230 : INFO : resetting layer weights\n",
      "2017-01-23 18:00:55,279 : INFO : training model with 8 workers on 2255 vocabulary and 381 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:00:55,280 : INFO : expecting 10669 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:56,012 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:00:56,012 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:00:56,012 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:00:56,022 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:00:56,022 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:00:56,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:00:56,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:00:56,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:00:56,038 : INFO : training on 1311425 raw words (902425 effective words) took 0.7s, 1351462 effective words/s\n",
      "2017-01-23 18:00:56,039 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:00:56,052 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\atypicalAntipsychotics_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:00:56,055 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:00:56,055 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: atypicalAntipsychotics_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for atypicalAntipsychotics...\n",
      "Begin sentences creation betaBlockers...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:58,029 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:00:58,029 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:00:58,029 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:00:58,069 : INFO : PROGRESS: at sentence #10000, processed 252058 words, keeping 11801 word types\n",
      "2017-01-23 18:00:58,101 : INFO : PROGRESS: at sentence #20000, processed 503517 words, keeping 17273 word types\n",
      "2017-01-23 18:00:58,108 : INFO : collected 17636 word types from a corpus of 530446 raw words and 21051 sentences\n",
      "2017-01-23 18:00:58,125 : INFO : min_count=10 retains 3667 unique words (drops 13969)\n",
      "2017-01-23 18:00:58,127 : INFO : min_count leaves 497632 word corpus (93% of original 530446)\n",
      "2017-01-23 18:00:58,135 : INFO : deleting the raw counts dictionary of 17636 items\n",
      "2017-01-23 18:00:58,138 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2017-01-23 18:00:58,140 : INFO : downsampling leaves estimated 384294 word corpus (77.2% of prior 497632)\n",
      "2017-01-23 18:00:58,141 : INFO : estimated required memory for 3667 words and 194 dimensions: 7524684 bytes\n",
      "2017-01-23 18:00:58,153 : INFO : resetting layer weights\n",
      "2017-01-23 18:00:58,197 : INFO : training model with 8 workers on 3667 vocabulary and 194 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:00:58,198 : INFO : expecting 21051 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:00:59,286 : INFO : PROGRESS: at 85.69% examples, 1638047 words/s, in_qsize 3, out_qsize 0\n",
      "2017-01-23 18:00:59,424 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:00:59,424 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:00:59,436 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:00:59,438 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:00:59,441 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:00:59,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:00:59,444 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:00:59,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:00:59,447 : INFO : training on 2652230 raw words (1921647 effective words) took 1.2s, 1653664 effective words/s\n",
      "2017-01-23 18:00:59,448 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:00:59,469 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\betaBlockers_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:00:59,470 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:00:59,470 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: betaBlockers_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for betaBlockers...\n",
      "Begin sentences creation calciumChannelBlockers...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:00,436 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:00,436 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:00,436 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:00,474 : INFO : PROGRESS: at sentence #10000, processed 245782 words, keeping 11844 word types\n",
      "2017-01-23 18:01:00,484 : INFO : collected 13052 word types from a corpus of 312962 raw words and 12682 sentences\n",
      "2017-01-23 18:01:00,497 : INFO : min_count=10 retains 2515 unique words (drops 10537)\n",
      "2017-01-23 18:01:00,499 : INFO : min_count leaves 287903 word corpus (91% of original 312962)\n",
      "2017-01-23 18:01:00,507 : INFO : deleting the raw counts dictionary of 13052 items\n",
      "2017-01-23 18:01:00,509 : INFO : sample=0.001 downsamples 58 most-common words\n",
      "2017-01-23 18:01:00,512 : INFO : downsampling leaves estimated 216876 word corpus (75.3% of prior 287903)\n",
      "2017-01-23 18:01:00,513 : INFO : estimated required memory for 2515 words and 329 dimensions: 7876980 bytes\n",
      "2017-01-23 18:01:00,519 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:00,555 : INFO : training model with 8 workers on 2515 vocabulary and 329 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:00,556 : INFO : expecting 12682 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:01,430 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:01,440 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:01,440 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:01,451 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:01,454 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:01,457 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:01,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:01,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:01,463 : INFO : training on 1564810 raw words (1084530 effective words) took 0.8s, 1329894 effective words/s\n",
      "2017-01-23 18:01:01,463 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:01,477 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\calciumChannelBlockers_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:01,479 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:01,480 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: calciumChannelBlockers_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for calciumChannelBlockers...\n",
      "Begin sentences creation estrogens...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:01,992 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:01,993 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:01,996 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:02,012 : INFO : collected 7208 word types from a corpus of 107545 raw words and 4316 sentences\n",
      "2017-01-23 18:01:02,019 : INFO : min_count=10 retains 1244 unique words (drops 5964)\n",
      "2017-01-23 18:01:02,020 : INFO : min_count leaves 93369 word corpus (86% of original 107545)\n",
      "2017-01-23 18:01:02,026 : INFO : deleting the raw counts dictionary of 7208 items\n",
      "2017-01-23 18:01:02,029 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2017-01-23 18:01:02,030 : INFO : downsampling leaves estimated 68098 word corpus (72.9% of prior 93369)\n",
      "2017-01-23 18:01:02,032 : INFO : estimated required memory for 1244 words and 233 dimensions: 2940816 bytes\n",
      "2017-01-23 18:01:02,039 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:02,059 : INFO : training model with 8 workers on 1244 vocabulary and 233 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:02,061 : INFO : expecting 4316 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:02,371 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:02,371 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:02,381 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:02,381 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:02,381 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:02,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:02,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:02,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:02,397 : INFO : training on 537725 raw words (340899 effective words) took 0.2s, 1396630 effective words/s\n",
      "2017-01-23 18:01:02,398 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-01-23 18:01:02,398 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:02,408 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\estrogens_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:02,410 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:02,411 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: estrogens_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for estrogens...\n",
      "Begin sentences creation nsaids...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:02,815 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:02,815 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:02,815 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:02,825 : INFO : collected 6881 word types from a corpus of 96702 raw words and 3861 sentences\n",
      "2017-01-23 18:01:02,841 : INFO : min_count=10 retains 1124 unique words (drops 5757)\n",
      "2017-01-23 18:01:02,842 : INFO : min_count leaves 83184 word corpus (86% of original 96702)\n",
      "2017-01-23 18:01:02,848 : INFO : deleting the raw counts dictionary of 6881 items\n",
      "2017-01-23 18:01:02,848 : INFO : sample=0.001 downsamples 64 most-common words\n",
      "2017-01-23 18:01:02,849 : INFO : downsampling leaves estimated 60256 word corpus (72.4% of prior 83184)\n",
      "2017-01-23 18:01:02,851 : INFO : estimated required memory for 1124 words and 242 dimensions: 2738064 bytes\n",
      "2017-01-23 18:01:02,855 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:02,871 : INFO : training model with 8 workers on 1124 vocabulary and 242 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:02,872 : INFO : expecting 3861 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:03,151 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:03,151 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:03,161 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:03,161 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:03,161 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:03,161 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:03,161 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:03,161 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:03,171 : INFO : training on 483510 raw words (301113 effective words) took 0.2s, 1408312 effective words/s\n",
      "2017-01-23 18:01:03,171 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-01-23 18:01:03,171 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:03,171 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\nsaids_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:03,181 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:03,183 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: nsaids_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for nsaids...\n",
      "Begin sentences creation opiods...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:04,759 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:04,759 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:04,759 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:04,796 : INFO : PROGRESS: at sentence #10000, processed 234961 words, keeping 12120 word types\n",
      "2017-01-23 18:01:04,825 : INFO : collected 16497 word types from a corpus of 453592 raw words and 19470 sentences\n",
      "2017-01-23 18:01:04,839 : INFO : min_count=10 retains 3230 unique words (drops 13267)\n",
      "2017-01-23 18:01:04,842 : INFO : min_count leaves 422371 word corpus (93% of original 453592)\n",
      "2017-01-23 18:01:04,851 : INFO : deleting the raw counts dictionary of 16497 items\n",
      "2017-01-23 18:01:04,854 : INFO : sample=0.001 downsamples 58 most-common words\n",
      "2017-01-23 18:01:04,855 : INFO : downsampling leaves estimated 318452 word corpus (75.4% of prior 422371)\n",
      "2017-01-23 18:01:04,858 : INFO : estimated required memory for 3230 words and 55 dimensions: 3036200 bytes\n",
      "2017-01-23 18:01:04,865 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:04,898 : INFO : training model with 8 workers on 3230 vocabulary and 55 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:04,900 : INFO : expecting 19470 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:05,727 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:05,727 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:05,727 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:05,737 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:05,737 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:05,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:05,737 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:05,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:05,747 : INFO : training on 2267960 raw words (1592179 effective words) took 0.8s, 2087628 effective words/s\n",
      "2017-01-23 18:01:05,749 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:05,765 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\opiods_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:05,766 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:05,766 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: opiods_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for opiods...\n",
      "Begin sentences creation oralHypoglycemics...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:06,384 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:06,394 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:06,394 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:06,404 : INFO : collected 7880 word types from a corpus of 137638 raw words and 5580 sentences\n",
      "2017-01-23 18:01:06,424 : INFO : min_count=10 retains 1445 unique words (drops 6435)\n",
      "2017-01-23 18:01:06,424 : INFO : min_count leaves 122123 word corpus (88% of original 137638)\n",
      "2017-01-23 18:01:06,430 : INFO : deleting the raw counts dictionary of 7880 items\n",
      "2017-01-23 18:01:06,430 : INFO : sample=0.001 downsamples 63 most-common words\n",
      "2017-01-23 18:01:06,431 : INFO : downsampling leaves estimated 88707 word corpus (72.6% of prior 122123)\n",
      "2017-01-23 18:01:06,433 : INFO : estimated required memory for 1445 words and 234 dimensions: 3427540 bytes\n",
      "2017-01-23 18:01:06,437 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:06,457 : INFO : training model with 8 workers on 1445 vocabulary and 234 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:06,457 : INFO : expecting 5580 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:06,838 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:06,839 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:06,844 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:06,846 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:06,851 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:06,854 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:06,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:06,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:06,858 : INFO : training on 688190 raw words (443328 effective words) took 0.3s, 1431576 effective words/s\n",
      "2017-01-23 18:01:06,859 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-01-23 18:01:06,859 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:06,868 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\oralHypoglycemics_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:06,868 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:06,869 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: oralHypoglycemics_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for oralHypoglycemics...\n",
      "Begin sentences creation protonPumpInhibitors...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:08,061 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:08,061 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:08,061 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:08,099 : INFO : PROGRESS: at sentence #10000, processed 230302 words, keeping 9660 word types\n",
      "2017-01-23 18:01:08,115 : INFO : collected 11243 word types from a corpus of 333475 raw words and 14535 sentences\n",
      "2017-01-23 18:01:08,125 : INFO : min_count=10 retains 2362 unique words (drops 8881)\n",
      "2017-01-23 18:01:08,125 : INFO : min_count leaves 312001 word corpus (93% of original 333475)\n",
      "2017-01-23 18:01:08,134 : INFO : deleting the raw counts dictionary of 11243 items\n",
      "2017-01-23 18:01:08,134 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2017-01-23 18:01:08,137 : INFO : downsampling leaves estimated 230368 word corpus (73.8% of prior 312001)\n",
      "2017-01-23 18:01:08,138 : INFO : estimated required memory for 2362 words and 206 dimensions: 5073576 bytes\n",
      "2017-01-23 18:01:08,144 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:08,174 : INFO : training model with 8 workers on 2362 vocabulary and 206 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:08,177 : INFO : expecting 14535 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:08,964 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:08,974 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:08,974 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:08,974 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:08,974 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:08,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:08,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:08,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:08,984 : INFO : training on 1667375 raw words (1151854 effective words) took 0.7s, 1577631 effective words/s\n",
      "2017-01-23 18:01:08,984 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:09,006 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\protonPumpInhibitors_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:09,006 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:09,007 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: protonPumpInhibitors_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for protonPumpInhibitors...\n",
      "Begin sentences creation skeletalMuscleRelaxants...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:10,049 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:10,059 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:10,059 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:10,094 : INFO : PROGRESS: at sentence #10000, processed 236263 words, keeping 16488 word types\n",
      "2017-01-23 18:01:10,105 : INFO : collected 18425 word types from a corpus of 298513 raw words and 12676 sentences\n",
      "2017-01-23 18:01:10,121 : INFO : min_count=10 retains 3075 unique words (drops 15350)\n",
      "2017-01-23 18:01:10,121 : INFO : min_count leaves 263712 word corpus (88% of original 298513)\n",
      "2017-01-23 18:01:10,131 : INFO : deleting the raw counts dictionary of 18425 items\n",
      "2017-01-23 18:01:10,131 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2017-01-23 18:01:10,134 : INFO : downsampling leaves estimated 202852 word corpus (76.9% of prior 263712)\n",
      "2017-01-23 18:01:10,134 : INFO : estimated required memory for 3075 words and 11 dimensions: 1808100 bytes\n",
      "2017-01-23 18:01:10,144 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:10,178 : INFO : training model with 8 workers on 3075 vocabulary and 11 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:10,180 : INFO : expecting 12676 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:10,726 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:10,726 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:10,726 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:10,726 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:10,726 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:10,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:10,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:10,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:10,736 : INFO : training on 1492565 raw words (1014274 effective words) took 0.5s, 2149997 effective words/s\n",
      "2017-01-23 18:01:10,736 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:10,757 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\skeletalMuscleRelaxants_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:10,759 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:10,759 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: skeletalMuscleRelaxants_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for skeletalMuscleRelaxants...\n",
      "Begin sentences creation statins...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:13,124 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:13,124 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:13,124 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:13,164 : INFO : PROGRESS: at sentence #10000, processed 257783 words, keeping 13546 word types\n",
      "2017-01-23 18:01:13,197 : INFO : PROGRESS: at sentence #20000, processed 513081 words, keeping 19771 word types\n",
      "2017-01-23 18:01:13,227 : INFO : collected 23692 word types from a corpus of 741783 raw words and 28886 sentences\n",
      "2017-01-23 18:01:13,249 : INFO : min_count=10 retains 4579 unique words (drops 19113)\n",
      "2017-01-23 18:01:13,250 : INFO : min_count leaves 697558 word corpus (94% of original 741783)\n",
      "2017-01-23 18:01:13,262 : INFO : deleting the raw counts dictionary of 23692 items\n",
      "2017-01-23 18:01:13,263 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2017-01-23 18:01:13,265 : INFO : downsampling leaves estimated 542657 word corpus (77.8% of prior 697558)\n",
      "2017-01-23 18:01:13,266 : INFO : estimated required memory for 4579 words and 467 dimensions: 19396644 bytes\n",
      "2017-01-23 18:01:13,278 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:13,348 : INFO : training model with 8 workers on 4579 vocabulary and 467 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:13,348 : INFO : expecting 28886 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-23 18:01:14,436 : INFO : PROGRESS: at 37.39% examples, 1014908 words/s, in_qsize 16, out_qsize 0\n",
      "2017-01-23 18:01:15,431 : INFO : PROGRESS: at 79.38% examples, 1077119 words/s, in_qsize 14, out_qsize 0\n",
      "2017-01-23 18:01:15,881 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:15,881 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:15,891 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:15,900 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:15,907 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:15,910 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:15,913 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:15,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:15,915 : INFO : training on 3708915 raw words (2713087 effective words) took 2.5s, 1093883 effective words/s\n",
      "2017-01-23 18:01:15,917 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:15,941 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\statins_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:15,943 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:15,944 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: statins_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for statins...\n",
      "Begin sentences creation triptans...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:16,546 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:16,546 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:16,556 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:16,566 : INFO : collected 8395 word types from a corpus of 151688 raw words and 6328 sentences\n",
      "2017-01-23 18:01:16,584 : INFO : min_count=10 retains 1540 unique words (drops 6855)\n",
      "2017-01-23 18:01:16,585 : INFO : min_count leaves 135313 word corpus (89% of original 151688)\n",
      "2017-01-23 18:01:16,592 : INFO : deleting the raw counts dictionary of 8395 items\n",
      "2017-01-23 18:01:16,592 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2017-01-23 18:01:16,595 : INFO : downsampling leaves estimated 96975 word corpus (71.7% of prior 135313)\n",
      "2017-01-23 18:01:16,595 : INFO : estimated required memory for 1540 words and 121 dimensions: 2260720 bytes\n",
      "2017-01-23 18:01:16,601 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:16,621 : INFO : training model with 8 workers on 1540 vocabulary and 121 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:16,622 : INFO : expecting 6328 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:16,970 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:16,971 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:16,973 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:16,977 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:16,980 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:16,982 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:16,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:16,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:16,987 : INFO : training on 758440 raw words (484883 effective words) took 0.3s, 1736543 effective words/s\n",
      "2017-01-23 18:01:16,989 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-01-23 18:01:16,990 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:16,997 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\triptans_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:16,999 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:16,999 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: triptans_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for triptans...\n",
      "Begin sentences creation urinaryIncontinence...\n",
      "Parsing sentences from training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:17,357 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-01-23 18:01:17,357 : INFO : collecting all words and their counts\n",
      "2017-01-23 18:01:17,357 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-23 18:01:17,368 : INFO : collected 6502 word types from a corpus of 72639 raw words and 3126 sentences\n",
      "2017-01-23 18:01:17,381 : INFO : min_count=10 retains 1004 unique words (drops 5498)\n",
      "2017-01-23 18:01:17,384 : INFO : min_count leaves 59811 word corpus (82% of original 72639)\n",
      "2017-01-23 18:01:17,388 : INFO : deleting the raw counts dictionary of 6502 items\n",
      "2017-01-23 18:01:17,388 : INFO : sample=0.001 downsamples 56 most-common words\n",
      "2017-01-23 18:01:17,391 : INFO : downsampling leaves estimated 42611 word corpus (71.2% of prior 59811)\n",
      "2017-01-23 18:01:17,391 : INFO : estimated required memory for 1004 words and 215 dimensions: 2228880 bytes\n",
      "2017-01-23 18:01:17,395 : INFO : resetting layer weights\n",
      "2017-01-23 18:01:17,410 : INFO : training model with 8 workers on 1004 vocabulary and 215 features, using sg=0 hs=0 sample=0.001 negative=5\n",
      "2017-01-23 18:01:17,411 : INFO : expecting 3126 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data loading and creating sentences\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-23 18:01:17,680 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-01-23 18:01:17,688 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-01-23 18:01:17,690 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-01-23 18:01:17,691 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-01-23 18:01:17,694 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-23 18:01:17,696 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-23 18:01:17,697 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-23 18:01:17,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-23 18:01:17,698 : INFO : training on 363195 raw words (213090 effective words) took 0.2s, 1081025 effective words/s\n",
      "2017-01-23 18:01:17,700 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2017-01-23 18:01:17,700 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-23 18:01:17,707 : INFO : saving Word2Vec object under C:\\Users\\CR107\\Dropbox\\PhD\\Experiments\\TREC_2004\\data\\word2vec\\urinaryIncontinence_chi2_features_10minwords_15context, separately None\n",
      "2017-01-23 18:01:17,707 : INFO : not storing attribute syn0norm\n",
      "2017-01-23 18:01:17,709 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model: urinaryIncontinence_chi2_features_10minwords_15context....\n",
      "Finished Model training and saving for urinaryIncontinence...\n"
     ]
    }
   ],
   "source": [
    "#iterate through a directory, load a file, sentence = filename.TIABSMh\n",
    "path = \"C:\\EPC_Data\\TREC_BROKEN\\No_Mh_Tag\"\n",
    "for file in os.listdir(path):\n",
    "    current_file = os.path.join(path, file)\n",
    "    filename, _, _ = file.split(\"_\")\n",
    "        \n",
    "    file_obj = pd.read_csv(current_file, sep=\",\", index_col='PMID')\n",
    "    corpus = file_obj.TIABSMh\n",
    "   \n",
    "    train_save_model(create_sentences(corpus, filename), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
